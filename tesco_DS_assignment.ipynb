{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "tesco_DS_assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/konradbachusz/AI_For_Music_Composition/blob/master/tesco_DS_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRhSYZeKx0aS"
      },
      "source": [
        "**General instructions:** \n",
        "- This task is intended to be a general DS assessment. If you have applied for an Operational Research role, please contact your recruiter. \n",
        "- Please, explain any step or though that you think may be important to evaluate your task. \n",
        "- The expected programming language is **python**\n",
        "\n",
        "- For the sake of the review, we **strongly prefer** to receive back a jupyter notebook containing all the code, comments and thoughts. This notebook should work from end to end, so we can `restart and run all` or  go through it, cell by cell, if we needed to do so."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MByQpzWgx0an"
      },
      "source": [
        "# TESCO STORES Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmURsmkPx0a4"
      },
      "source": [
        "At Tesco, the location of a retail store plays a huge role in its commercial success. Our Stores Team use various data sources to better understand the potential of candidate locations for new stores in the UK. They need data science help in designing a model that can predict the future sales **[normalised_sales]** of a store based on location characteristics. Your task is to examine the provided dataset and answer the questions below.\n",
        "\n",
        "Dataset files\n",
        "* `tesco-dataset/train.csv`\n",
        "* `tesco-dataset/test.csv`\n",
        "\n",
        "Columns\n",
        "* `location_id`: id of Tesco property location\n",
        "* `normalised_sales`: normalised sales value of Tesco store\n",
        "* `crime_rate`: crime rate in the area (higher means more crime)\n",
        "* `household_size`: mean household size in the area\n",
        "* `household_affluency`: mean household affluency in the area (higher means more affluent)\n",
        "* `public_transport_dist`: index of public transport availability in the area\n",
        "* `proportion_newbuilds`: proportion of newly built property in the area\n",
        "* `property_value`: average property value in the area\n",
        "* `commercial_property`: percentage of commercial properties in the area\n",
        "* `school_proximity`: average school proximity in the area\n",
        "* `transport_availability`: availability of different transport\n",
        "* `new_store`: new Tesco store opened recently\n",
        "* `proportion_nonretail`: proportion of non-retail commercial properties in the area\n",
        "* `competitor_density`: density of competitor retailers\n",
        "* `proportion_flats`: proportion of blocks of flats in the area\n",
        "* `county`: county code of the area"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXy0UVJTx0bL"
      },
      "source": [
        "## Q1\n",
        "Before diving into the modelling, you are given the dataset and the Stores Team expect you to come back with an analysis of the data and any concerns you may have about it. They would also like to know which other information you think would be useful to collect for future developments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4Jm3z80x0bX"
      },
      "source": [
        "## Q2\n",
        "Build a model that can predict store sales based on the provided area features. Please show how you developed the model and report how well your model is performing. ***Constraint:*** Please use Random Forest as the model family to solve this problem. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4F9aC67tx0bh"
      },
      "source": [
        "## Q3\n",
        "The dataset contains a test set of potential store locations. Use your developed model to predict the sales value in these areas and explain what recommendations you would give to the Stores Team to use it. Use any tools that may help you to share your findings with product owners and other non-technical decision makers in the team. Complete this task by explaining how you would improve the current results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Weltx7b3x0bu"
      },
      "source": [
        "-------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yi4We5NIx0cW"
      },
      "source": [
        "## Masked Dataset\n",
        "\n",
        "You are given the following small dataset, which has been completely masked for privacy reasons. Please train the best model you can come up with to predict the target variable `y` based on the features `x1` and `x2`. Explain every step you take. \n",
        "\n",
        "Assuming that this model will be used for making decisions involving important sums of money, provide any comments that you think you should be giving to the business as a technical expert.\n",
        "\n",
        "Dataset files\n",
        "* `masked_dataset/train.csv`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTk_DCjxx6rc"
      },
      "source": [
        "\n",
        "# Things to consider\n",
        "*   Outlier detection/anomaly detection\n",
        "*   encoding\n",
        "\n",
        "*   Cross validation\n",
        "*   Feature engineering\n",
        "* Hyper parameter tuning\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORGV8GN-yRmT"
      },
      "source": [
        "Time spent \n",
        "26 Sep 10:30-11:30: 1h\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOjsqUQZyNVZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJa5VUvdz31f"
      },
      "source": [
        "#Q1\n",
        "\n",
        "TODO\n",
        "* Load train/test data and append it\n",
        "* EDA:\n",
        "** Pandas profiling\n",
        "** Missing values\n",
        "** Outliers\n",
        "** Correlations\n",
        "** Data quality\n",
        "** Graphs\n",
        "** Distributions\n",
        "** Useful fuuture data\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ggf4132ySgF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ib2cFDN035g"
      },
      "source": [
        "#Q2\n",
        "* Train CV split\n",
        "* Feature engineering\n",
        "* * Polynomials?\n",
        "* Dropping correlated features\n",
        "* Random forest feature selection\n",
        "* RFE feature selection\n",
        "* Random forest\n",
        "* Metrics: R2, loss\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSFTP32B16Bl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqJVw3FG2PCA"
      },
      "source": [
        "#Q3\n",
        "* Predict test set\n",
        "* Shap \n",
        "* Lime\n",
        "* Recommendations in a slides\n",
        "* Improving results: xgboost, deep learning, more data, better features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4M4EV1yb3MqP"
      },
      "source": [
        "# Masked dataset\n",
        "* train, valid, test split\n",
        "* Feature engineering: feature tools\n",
        "* * Polynomials\n",
        "* Feature selection\n",
        "  * XGB feature selection\n",
        "  * RFE\n",
        "* Models\n",
        "  * XGBoost\n",
        "  * Deep learning\n",
        "* Shap\n",
        "* Comments on the model: \n",
        "  * How it works\n",
        "  * Performance\n",
        "  * Limitations\n",
        "  * Probability confidence\n",
        "  * Explainability\n"
      ]
    }
  ]
}